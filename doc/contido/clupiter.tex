\chapter{Clúpiter}
\label{chap:conceptos_basicos}

\lettrine{P}{ara} comprender el objetivo del proyecto y su propuesta de valor, primero es necesario entender las características del mismo, la justificación de las mismas, y el funcionamiento de sus componentes más primitivos.

\section{Nombre y Marca Corporativa}
Si bien este no es un elemento altamente importante en un proyecto de ingeniería como este, si que es conveniente y nunca está de más otorgarle personalidad mediante la creación de un nombre e isotipo para el mismo.

El nombre del clúster es \textbf{Clúpiter} (ClúPIter): una mezcla entre las palabras ``Clúster'' y el ``PI'' de la \acrlong{rpi}, que de forma muy conveniente recuerda en su segunda parte a Júpiter. Este es a su vez planeta del sistema solar junto con el (enano) Plutón, nombre del clúster del GAC\footnote{\url{http://pluton.dec.udc.es}}. Es cuanto menos paradógico que el cluster en miniatura sea Júpiter, y el real sea Plutón\dots

En cuanto a la marca del cluster, éste no puede quedar sin un logo, que se muestra a continuación:

TODO AQUÍ VA EL ISOLOGO %% INSERTAR ISOLOGO

\section{Precedentes}
Existen multitud de amateurs y amantes de la informática que como proyecto personal deciden montar un clúster de \acrlong{rpi}s, entre los que por ejemplo se encuentra Jeff Geerling\footnote{\url{https://www.youtube.com/user/geerlingguy}}.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.75\textwidth]{img/cluster-pi-home.png}
  \caption{Mini-cluster casero basado en \acrlong{rpi} \cite{geerling_intro_cluster}}
  \label{fig:cluster-pi-ejemplo}
\end{figure}

Además, en el mundo académico también ha habido aproximaciones muy similares al trabajo desarrollado, destacando \textit{Wee Archie}, un mini-supercomputador muy similar al de este proyecto de mayor tamaño, que permite explicaciones algo más interesantes con sus pantallas de matriz de LED.

Como se puede leer en la página web del proyecto \cite{wee_archie_webpage}, este es un supercomputador del tamaño de una maleta, que al igual que Clúpiter, sirve para explicar el funcionamiento de su hermano mayor, el supercomputador ARCHER\footnote{\url{https://www.archer.ac.uk}}.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.75\textwidth]{img/wee-girl.jpg}
  \caption{Mini-supercomputador Wee Archie}
  \label{fig:wee_archie_girl}
\end{figure}

\section{Conceptos Básicos}
\subsection{Clústers}
Los clústers, en concreto para este proyecto de alto rendimiento, son conjuntos de ordenadores diseñados para ofrecer altas prestaciones de cálculo.

Estos clústers pueden ser homogéneos o heterogéneos, siendo compuestos por computadores con la misma arquitectura y capacidades, o con arquitecturas o capacidades diferentes, respectivamente.

En el caso de Clúpiter, éste es un clúster muy homogéneo, ya que está compuesto por ocho mini-computadores exactamente iguales.

\subsection{Raspberry Pi 4 Model B}
Cada aproximadamente dos años, la Raspberry Pi Foundation saca una nueva versión de su compacto y más exitoso producto: la \acrlong{rpi}, o por sus siglas \acrshort{rpi}. Estos pequeños computadores vienen en diversos formatos de forma, pero el que ha catapultado esta plataforma al éxito ha sido el formato que denominan \textit{Standard}\footnote{85.6 mm × 56.5 mm}.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.75\textwidth]{img/rpi_parts/rpi_base.jpg}
  \caption{\acrlong{rpi} 4 Model B}
  \label{fig:rpi_base}
\end{figure}

Siendo cada versión mucho más potente que la anterior, y costando aproximadamente el mismo precio, está claro que la Raspberry Pi Foundation está haciendo un excelente trabajo aportando valor a este segmento del bajo consumo y coste.

La \acrlong{rpi} 4B (4 Model B) es la versión más nueva de formato standard, y por ello ha sido la elección para constituir la base del clúster. Las especificaciones de la misma son:

\subsubsection{CPU}
La CPU de este nuevo modelo es la \textbf{Broadcom BCM2711}, un procesador con arquitectura ARMv8-A y 4 núcleos Cortex-A72.

Estos núcleos cuentan con un \textit{pipeline} de 15 etapas, ejecución OOO (\textit{out-of-order}) y predictor de saltos, entre otros.

\begin{wrapfigure}[5]{r}{0.18\textwidth}
  \centering
  \includegraphics[width=0.18\textwidth]{img/rpi_parts/rpi_cpu.jpg}
  \label{fig:rpi_cpu}
\end{wrapfigure}
Además, cuenta con 48KB de L1I y 32KB de L1D por núcleo, así como 1MB de L2 compartido (256KB por núcleo). Esto emparejado con un único chip de 2GB de memoria LPDDR4-2400, es suficiente para un uso doméstico sencillo, pero quizás no sea la mejor disposición para el cómputo intensivo como se verá más adelante.
% TODO INSERTAR REF?????

\subsubsection{GPU/VPU}
A pesar de que el integrado que se muestra en la foto del apartado superior es un \acrshort{soc} (\textit{\acrlong{soc}}), se ha preferido tratar la CPU y la GPU/VPU por separado. Y es que los gráficos integrados de esta última \acrlong{rpi} son una importante mejora sobre la VideoCore IV que equipaban modelos anteriores.

La GPU en la \acrshort{rpi}4 es la VideoCore VI, y cuenta con multitud de soporte para multimedia y una potencia gráfica aceptable. En concreto, acelera por hardware H.265 (4Kp60 decode), H.264 (1080p60 decode, 1080p30 encode), y soporta OpenGL ES, 3.0.

\begin{wrapfigure}[7]{r}{0.32\textwidth}
  \centering
  \includegraphics[width=0.32\textwidth]{img/vulkan_logo.png}
  \label{fig:vulkan_logo}
\end{wrapfigure}
Además, y lo que considero más interesante, es que posteriormente al lanzamiento se comenzó para esta gráfica el desarrollo de un driver de Vulkan: un estándar abierto de última generación para programación de gráficos, pero que también se puede emplear para cómputo. Esto es una fantástica noticia, ya que permite acelerar ciertas cargas de trabajo aprovechando la inmensa capacidad de cómputo paralelo de estos dispositivos, siendo una de las más habituales en estos dispositivos la transformada de Fourier.

Realizar algún tipo de programa para computación \acrshort{gpgpu} (\textit{\acrlong{gpgpu}}) en Vulkan queda fuera de lo que pretende abarcar este trabajo, pero es un interesante proyecto para la realización de alguna otra iteración sobre esta plataforma.

\subsubsection{E/S}
En términos de entrada/salida la \acrshort{rpi}4B cuenta con multitud de puertos. Los que se van a usar son Gigabit Ethernet y USB 3.0, sin embargo equipa de serie otros muchos ortos puertos en el \acrshort{gpio} (\acrlong{gpio}), como son DSI (\textit{Display Serial Interface}), CSI (\textit{Camera Serial Interface}), I2C (\textit{Inter-Integrated Circuit}), UART (\textit{Universal Asynchronous Receiver-Transmitter}), SPI (\textit{Serial Peripheral Interface}), y video compuesto, así como dos salidas HDMI.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.85\textwidth]{img/rpi_parts/rpi_gpio.png}
  \caption{Pines GPIO de la \acrlong{rpi} 3, idénticos a los de la 4}
  \label{fig:rpi_gpio_pinout}
\end{figure}

\subsection{MPI}
\begin{wrapfigure}[5]{r}{0.19\textwidth}
  \centering
  \includegraphics[width=0.19\textwidth]{img/ompi_logo_2.png}
  \label{fig:ompi_logo}
\end{wrapfigure} 

\acrshort{mpi} (\acrlong{mpi})\footnote{\url{https://www.mpi-forum.org}} es un estándar de paso de mensajes diseñado para la computación en arquitecturas paralelas. Esto es, define la sintaxis y semántica de las rutinas que exponen las diferentes implementaciones.

Entre estas implementaciones hay algunas muy importantes y que son estándares de facto, como:
\begin{itemize}
  \item\textbf{OpenMPI}\footnote{\url{https://www.open-mpi.org}}: Implementación libre mantenida por un consorcio de académicos, investigadores y socios que ofrece elevada eficiencia y flexibilidad a quien la implementa. Además es la librería \acrshort{mpi} contra la que se compilan por defecto los ejecutables en Arch Linux.
  \item\textbf{MPICH}\footnote{\url{https://www.mpich.org}}: Otra implementación libre de MPI muy similar a OpenMPI en rendimiento, flexibilidad y modo de desarrollo.
  \item\textbf{Intel MPI}\footnote{\url{https://software.intel.com/content/www/us/en/develop/tools/oneapi/components/mpi-library.html}}: Implementación propietaria de \acrshort{mpi} por parte de Intel. Está especializada en productos de la propia marca y optimiza para ellos, por lo que suele arrojar un mayor rendimiento que las contrapartes libres.
\end{itemize}

\subsubsection{Envío de datos en \acrshort{mpi}}
\acrshort{mpi} funciona mediante el uso de \textbf{primitivas}, es decir, operaciones que realizan algún tipo de cálculo y/o transferencia de datos entre nodos de un mismo \textbf{comunicador}.

La base de \acrshort{mpi} son las primitivas de envío y recepción de datos, y existen dos funciones de envío y recepción \textbf{síncronas} (esto es, la llamada a la función solamente termina cuando todos los miembros involucrados la ejecución de dicha función han terminado).
\begin{itemize}
  \item \textbf{MPI\_Send}: Envía un mensaje a destino, y espera a que el receptor esté listo para recibirlo. 
  \item \textbf{MPI\_Recv}: Espera a que llegue un mensaje del origen, y cuando éste está listo para enviarlo, lo recibe.
\end{itemize}

Estas funciones tienen su contraparte para programación asíncrona, que puede arrojar un mayor rendimiento, pero también requiere un extra de complejidad y puede no ser trivial. Las funciones básicas para realizar programación asíncrona con \acrshort{mpi} son \textbf{MPI\_Isend} y \textbf{MPI\_Irecv}. A su vez son necesarias para chequear el estado de la ejecución asíncrona las funciones \textbf{MPI\_Test} (asíncrona) y \textbf{MPI\_Wait} (síncrona).

\subsubsection{Primitivas de grupo en \acrshort{mpi}}
Otra funcionalidad de \acrshort{mpi} ampliamente utilizada son las primitivas de grupo. La mayoría de ellas tienen en común que:
\begin{itemize}
  \item Son funciones llamadas por todos los procesos del comunicador.
  \item La comunicación es síncrona.
\end{itemize}

Las primitivas más sencillas y comunes de MPI, desde el punto de vista del proceso raíz, son las siguientes:
\begin{itemize}
  \item \textbf{MPI\_Bcast}: Emite (hace \textit{broadcast}) el mensaje a todos los procesos del comunicador.
  
  \begin{figure}[H]
    \vspace*{0.5cm}
    \centering
    \resizebox {0.8\textwidth} {!} {
    \input{pgf/MPI_Bcast.pgf}
    }
    \caption{Visualización de MPI\_Bcast \cite{cheung_mpi}}
    \label{fig:mpi_bcast}
  \end{figure}

  \item \textbf{MPI\_Scatter}: Distribuye equitativamente el mensaje entre todos los procesos del comunicador.

  \begin{figure}[H]
    \vspace*{0.5cm}
    \centering
    \resizebox {0.8\textwidth} {!} {
    \input{pgf/MPI_Scatter.pgf}
    }
    \caption{Visualización de MPI\_Scatter \cite{cheung_mpi}}
    \label{fig:mpi_scatter}
  \end{figure}

  \item \textbf{MPI\_Gather}: Recoge varios fragmentos de un mensaje y los combina. Es la operación inversa al scatter.

  \begin{figure}[H]
    \vspace*{0.5cm}
    \centering
    \resizebox {0.8\textwidth} {!} {
    \input{pgf/MPI_Gather.pgf}
    }
    \caption{Visualización de MPI\_Gather \cite{cheung_mpi}}
    \label{fig:mpi_gather}
  \end{figure}

  \item \textbf{MPI\_Reduce}: Recoge al igual que en el scatter los fragmentos del mensaje, pero en lugar de almacenarlos como tal, aplica una operación sobre ellos.

  \begin{figure}[H]
    \vspace*{0.5cm}
    \centering
    \resizebox {0.8\textwidth} {!} {
    \input{pgf/MPI_Reduce.pgf}
    }
    \caption{Visualización de MPI\_Reduce \cite{cheung_mpi}}
    \label{fig:mpi_reduce}
  \end{figure}

\end{itemize}

%%%% TODO INSERTAR FIGURAS CON TIKZ

